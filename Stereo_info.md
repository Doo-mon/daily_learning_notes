# Stereo Images and Videos Record

## 双目图像视频超分

***
## 前期的调研

当前任务————先把23年的双目超分的那篇总结看一遍  看看大家的方法


多阶段？




从结合新的工作考虑？
+ 



从intra模块考虑？
+ 增强图像内部信息的获取




从inter模块考虑？
+ 增强双视角图像之间信息的获取
  


从数据集上面考虑？
+ 数据集能不能使用生成的？



从工作统一性上面考虑？
+ 能不能和其他工作结合  比如可以去做去雨 去雾 



从单一角度进行提高？
+ 就比如比赛中三个赛道  针对PSNR  针对感知分数  针对真实场景的超分







### 超分 难点？
捕获双目图像中互补的信息

高度依赖双目图像的内在属性 比如 视差特征 深度信息 遮挡 边界
（可以用深度图重建的效果验证StereoISR的效果？）

双目图像是通过双目系统在不同的方向和角度捕获的，不同视图之间存在差异（曝光） 和不兼容（视差）

不同深度的物体的立体对应可能会有很大的差异
左右视图之间的遮挡阻碍了对应关系的合并

现实场景的退化比双三次场景更加复杂（可能还需要考虑现实场景的退化）
感知质量和立体一致性对于立体图像的视觉效果也很重要



***
## 0 一些相关信息的网站，放在这里方便查询
[1]()
[2]()
[3]()
[4]()





***
## 1 从别人论文中学习到的idea

1. CVGSR: Stereo Image Super-Resolution with Cross-View Guidance
    这篇文章是暂时还没有发表的
    __主要可以学习他的交叉模块__  
    结合了CNN捕获短程依赖关系和Transformer捕获长程依赖关系的能力

    其中还设计了一个纹理损失函数  获取更好的视觉感知 而不是仅仅考虑PSNR指标（估计是创新点不足，另外找的一个点）


    <p align="center">
    <img src=./images/stereo/CVGSR_arch.png width=90%>
    </p>
    首先利用特征提取模块 分别生成 左图像和右图像的特征映射（与之前的方法都比较类似）
    然后使用一个交叉视角交互模块 CVIM 进行不同视角信息的交换
    最后再接上一个重建模块（以及一个用到烂的残差相加）得到最后的高分辨图像




2. 双目超分比赛赛道一的冠军 用的是 transformer + cnn 的方案 两阶段
   __可以学习一下结合使用两种方式的这种思想__ 可以分别利用对方的长处，上面那篇论文也有类似的思想
    <p align="center">
    <img src=./images/stereo/HTCAN_arch.png width=90%>
    </p>


3. 





<!-- 废弃的文本内容 -->


<!-- 双目视频超分？
or
双目视频压缩？

实验表明 用深度学习模型来压缩实在是太慢了 传统方式一下子就解决的事情
做视频压缩这个方向不太现实。 -->



<!-- ***
## 2 

#### 对于S-NeRV中的各个文件夹
注意现在的S-NeRV是基于E-NeRV的代码进行修改的，因为E-NeRV的代码更加系统

现在感觉这个方向有点不太行


+ videodata 用于存放原始的视频数据
+ data 用于存放切分成帧的视频数据 利用video_data_pre.py进行切分
    分成两种，一种是合并的图像，另外一种是切分成左右两个视角帧的图像

+ datasets 用于生成训练所需要的dataset
+ cfgs 用于更改训练和模型的配置文件 -->





<!-- ### 压缩 难点？

需要找到一些对比的方法？
传统的视频压缩方式？


视频信息之所以存在大量可以被压缩的空间，是因为其中本身就存在大量的数据冗余
时间冗余 视频相邻两帧之间内容相似 存在运动关系
空间冗余 某一帧内部的相邻像素存在相似性
编码冗余 视频中不同数据出现的概率不同
视觉冗余 观众的视觉系统对视频中的不同部分的敏感度不同 -->