# Embodied AI 具身智能


[代码环境](#代码环境未完善)


***
### 相关调研

目前的困难：拥有一个能在不同环境中操纵任意物体的机器人一直都是一个遥不可及的目标
**部分原因是因为 缺乏用于训练这类机器人的各种机器人数据集 同时也缺乏能够生成此类数据集的通用机器人**

#### 1. 多任务机器人模型 RT系列（robot transformer） 和 roboagent

应用于真实世界的机器人模型的训练数据往往需要手动操作来收集 而且不便于跨机器人使用 （相较于CV和NLP领域更为困难）。因此，建立多任务机器人模型为下游任务服务以减轻数据收集工作的压力就尤为重要。
**Q:有个小疑问，如果某些小任务本来就不能完成呢？换句话说，CV和NLP领域都是从小往大发展的，那机器人为什么从上往下发展有希望成功呢？**
以往建立的大型多任务策略如Gato或者instruction following methods等往往专注于训练集内的任务，在新任务上难以泛化或表现较差，难以满足实际需求

transformer的高容量特点能够很好地兼顾多任务的学习目标，但对于机器人，能够实时高效运行也是必不可少的需求，然而传统的transformer无法满足这一需求



#### 2. 其他

**PaLM-E** 假定了存在着一个低层级的 **policy 或者 规划器** 能够将输出的 决定 转化为 低层级的动作  => 这就意味着还不能一步到位

对于不同模态的输入用了不同的编码器进行编码

#### 3.综述小结  Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis

文章把 应用在机器人技术中的基础模型 分为两个大类
**Foundation Models used in Robotics** 和 **Robotic Foundation Models**



4.1.1 **视觉基础模型 和 视觉语言模型 应用在 机器人感知**

+ Object and Scene Representations

ConceptFusion [203] 根据 RGB-D 输入和基础模型的特征构建开放集多模态 3D 地图，允许从不同模态（例如图像、音频、文本和点击交互）进行查询。

CLIP-Fields [202] 将场景的 RGB-D 图像编码为可语言查询的潜在表示，作为内存结构中的元素，机器人策略可以灵活地检索。

VLMap [201] 使用 LSeg [151] 提取每像素表示，然后与深度信息融合，以创建 3D 地图。然后，对该语义 3D 地图进行下投影，以获得具有每像素嵌入的 2D 地图；然后，这些嵌入可以与 LSeg 中的语言嵌入相匹配，以获得 2D 地图的每像素语义掩码。

LM-Nav [204] 是一个很好的例子：它使用 LLM 从自然语言指令中提取导航中使用的地标。然后，这些地标描述以及图像观察结果将通过 VLM 建立在预先构建的图表中。然后，规划模块用于将机器人导航到指定的地标。

F3RM [197] 和 GNFactor [198] 通过与 NeRF 和泛化 NeRF 相结合，将 2D 基础模型特征提取到 3D 空间中。GNFactor [198] 也在政策学习中应用了这些提取的特征。 Act3D [206] 采用类似的方法，但通过感测深度构建 3D 特征场

+ State Estimation and Localization

LEXIS [207] 和 FM-Loc [199]，探索使用 CLIP [53] 功能来执行室内定位和建图。

AnyLoc [208] 探索了密集基础模型特征的属性，并将其与无监督特征聚合技术相结合，以在任何地点、任何时间和任何视图下大幅实现最先进的地点识别，展示了SLAM 的自监督基础模型特征。

+ Interactive Perception

MOSAIC [200]利用 LMM 来加速获取统一的多感官对象属性表示；作者展示了他们的框架在类别识别和模糊目标对象获取任务中的竞争性能，尽管存在干扰对象，但在零样本传输条件下。

4.1.2 **大语言模型 和 视觉语言模型 应用在 任务规划**

（这节 focus 在任务级规划，下一节 focus 在运动级规划）任务级规划是将复杂的任务划分为可操作的小步骤。

**这些任务级规划方法不必担心环境中这些子任务的精确执行，因为它们可以利用一组预定义/预训练的技能，然后使用 LLM 来简单地找到合适的任务。组合技能以实现预期目标的方法。**

SayCan [24] 是任务级规划的一个典型例子：它使用 LLM 来规划高级任务，例如，“我洒了饮料，你能帮忙吗？”。然后它给出了具体的任务计划，比如去柜台、找海绵等等。

VLP [217] 旨在通过额外的文本到视频动态模型来改进长期规划方法。

LM-ZSP [219] 将此任务级粒度引入为可操作的步骤

Text2Motion [220]使用类似的想法并提高了基于语言的操作任务的成功率。

**上面的模型都是输出文本的命令，下面这些可以直接输出代码**

一些作品如 ProgPrompt [221]、Code as Policy [216]、GenSim [222] 等使用 LLM 以代码生成的形式获取任务计划。

**其他**

SayPlan [224] 采用 3D 场景图 (3DSG) 表示来管理广阔环境的复杂性。


4.1.3 **大语言模型 和 视觉语言模型 应用在 动作生成**

**如果不首先使用动作数据对这些模型进行微调，仅通过提示现成的 LLM/VLM 来直接控制机器人可能具有挑战性，甚至可能无法实现**
**不像任务级规划，对于路径点这样的高级动作或者关节角这样的低级动作，都是没有语义意义**

ReasonedExplorer [225] 和 Not Train Dragon [228] 提出了这样一个接口：使用 LLM 作为扩展边界的评估器，这些边界被定义为探索的潜在路径点（通常在二维空间中）；在这里，LLM 的任务是根据给定观察结果与预期目标之间的相似性对边界进行评分。

VoxPoser [227] 应用 VLM 来获得运动规划中使用的可供性函数（在原始论文中称为 3D 值图）。

**一些论文研究了使用 LLM 直接输出较低级别的 action**

Prompt2Walk [229] 使用 LLM 通过从物理环境收集的少量提示直接输出关节角度。它研究 LLM 是否可以通过在环境反馈数据（观察-行动对）的背景下学习来充当低级控制器。

Saytap [26] 引入了一种利用脚部接触模式作为动作表示的新颖概念。在此模型中，语言模型输出“0”表示没有接触，输出“1”表示与地板接触，从而使大型语言模型 (LLM) 能够为四足运动任务（例如跳跃和慢跑）生成零样本可操作命令。

机器人学中的语言奖励 [230-232] [182, 226] 是比通过法学硕士直接采取行动更通用的方法；这些方法涉及使用 LLM 作为生成器来合成基于强化学习的策略的奖励函数，因此通常不受机器人实施例的限制

LLM 的奖励合成方法可以产生人类难以设计的奖励，例如，Eureka [182] 表明，它使机器人能够学习**灵巧的转笔任务**，而使用人类奖励设计被认为非常困难。


4.1.4 **机器人接地**






















***
### 相关术语

#### 1. Affordance 可供性
Affordance 强调了物体属性与个体行为之间的关系。

+ 例如，一个椅子提供了“坐”的可能性，一个按钮提供了“按”的可能性。**这种可能性并不完全取决于物体的物理属性，还取决于个体的能力和意图**

+ 在机器人学中，理解和利用 affordance 意味着机器人能够识别和理解其周围环境中的物体，并根据这些物体提供的动作可能性来规划和执行任务。例如，一个机器人可能识别到桌子上的杯子是可拿起的（提供了“抓取”的 affordance）

#### 2. Grounding 接地
Grounding 涉及到如何使计算模型能够理解和表示现实世界的信息

+ 表示符号与现实世界的连接：比如某些单词、图像中的物体需要和现实世界中具体的事物或者概念相联系，grounding就是建立这种联系的过程，在NLP中，模型需要理解单词或者短语的实际含义。
+ 感知数据的理解：在视觉或听觉任务中，grounding涉及到如何从原始感知数据（如图像或声音）中提取有意义的信息，并将其与具体的概念或对象关联起来。
+ 多模态学习：在处理多种类型的数据（如文本和图像）时，grounding有助于模型理解不同模态之间的关系和交互，例如，理解一张图片和描述这张图片的文本之间的关系。
+ 上下文理解：在复杂的任务中，如对话系统或机器翻译，grounding还包括了理解上下文信息，使得模型能够在特定上下文中更加准确地理解和生成回应。



















***
### 代码环境（未完善）

如果是直接通过conda create的方式，会有比较多的包需要额外安装
```shell
pip install pillow # PIL

pip install numpy
pip install gcsfs # install gcsfs to access Google Storage
pip install tensorflow==2.12.0 # 不要安装最新的 不知道为什么最新的一直有问题

pip install tensorflow_datasets
pip install tfds-nightly # 要获取最新的数据集要安装这个包
```







**执行完下面这个后 以后直接用 `xemb` 激活环境 同时切换目录**

```shell
conda create -n xemb python=3.9
# 修改系统变量 
vim ~/.bashrc
# 在最后一行添加下面这个
alias xemb="source activate xemb; cd ~/zhihao/new_storage/open_x_embodiment"
alias cd-xemb="cd ~/zhihao/new_storage/open_x_embodiment"
# 退出后source一下
source ~/.bashrc
```


***
### 遇到的一些问题

**报错及解决**
1. TqdmWarning: IProgress not found 警告通常出现在使用 tqdm 库（一个快速、可扩展的Python进度条库）时，尤其是在 Jupyter 笔记本或其他基于 Web 的环境中
**重新安装即可 `pip install ipywidgets --upgrade`**

2. 在使用pip命令的时候，报这个错误 sys.stderr.write(f"ERROR: {exc}") 
   **主要原因也是版本不对，重新安装pip**



***
### 参考资料

1. 【VALSE2023】0611《Workshop ：机器人具身智能》
https://www.bilibili.com/video/BV1L8411R7f7/?spm_id_from=333.999.0.0

2. xxx
